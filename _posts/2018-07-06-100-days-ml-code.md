---
title:  "100 Days Of Machine Learning Code"
date:   2018-07-06 23:22:00 +0200
last_modified_at: 2018-07-27T07:20:00+02:00 
categories: General 
---
Here I pledge to dedicate 1 hour to coding or learning Machine Learning for the next 100 days!

## Day 0: July 06, 2018 

**Today's Progress**: 

Learned about word embedding in Sequence Models course on [Coursera](https://www.coursera.org), such as Word2Vec, negative sampling, GloVe word vectors and sentiment classification.

**Thoughts:** 

It is interesting to know about how the word embedding algorithms are simplified over time while still being able to achieve very good results. Being simpler in this case gets even better performance.

**Link to work:** None 

## Day 1: July 07, 2018 

**Today's Progress**: 
* Learned basics and intuitions about Singular Vector Decomposition(SVD). Here are two very good videos explaining it:
    * [How to do Singular Value Decomposition](https://www.youtube.com/watch?v=EfZsEFhHcNM): step for step explanation.
    * [Dimensionality Reduction: Singular Value Decomposition](https://www.youtube.com/watch?v=P5mlg91as1c): intuitive practical example.
* Continued with `Sequence Models` course on Coursera.
    * Learned [Debiasing word embeddings](https://www.coursera.org/lecture/nlp-sequence-models/debiasing-word-embeddings-zHASj). Concepts about how to debias the biased word embeddings. For example, "doctor" should not have a closer relation to "Man" than "Woman". And "mother" and "father" should be equally similar at the "gender" axis.
    * Programming assignments
        * Debiasing word embeddings.
        * Emojify (word embedding + LSTM) - outputs a suitable emoji given a sentence. 

**Thoughts:** 
* `SVD` is so simple yet powerful. I should try to use it to solve some real problems.
* I am still not familiar with `Keras` syntax. 
* It is quite impressive to see how well the "Emojify" works even with a relatively small data set.

**Link to work:** 

Due to the honor code on Coursera, I am not allow to share my code in the course publicly. 

## Day 2: July 08, 2018 

**Today's Progress**: 
* Learned how t-SNE works by watching [StatQuest: t-SNE, Clearly Explained](https://www.youtube.com/watch?v=NEaUSP4YerM).
* Continued with `Sequence Models` course on Coursera.
    * [Basic Models](https://www.youtube.com/watch?v=JNyDLARW9x4)
    * [Picking the most likely sentence](https://www.youtube.com/watch?v=xfplLFXsdjc)
    * [Beam Search](https://www.youtube.com/watch?v=RLWuzLLSIgw)
    * [Refinements to Beam Search](https://www.youtube.com/watch?v=gb__z7LlN_4)
    * [Error analysis in Beam Search](https://www.youtube.com/watch?v=gGw_YS7qCdg)
    * [Bleu Score](https://www.youtube.com/watch?v=DejHQYAGb7Q)
    * [Attention Model Intuition](https://www.youtube.com/watch?v=SysgYptB198)
    * [Attention Model](https://www.youtube.com/watch?v=quoGRI-1l0A)

**Thoughts:** 
* Beam Search seems like an engineering approach to cope with data set where other exact algorithms like BFS and DFS will be too time consuming. Are there really no better way than Beam Search?
* From the error analysis in beam search, I learned the concept of how to prioritize error sources, in this case in beam search or in RNN itself. Similarly, when training a Neural Network, it also has to be determined whether it is overfitting or underfitting to locate the most important error sources.

**Link to work:** None

## Day 3: July 09, 2018 

**Today's Progress**: 
* Continued with and finished `Sequence Models` course on Coursera.
    * Videos
        * [Speech recognition](https://www.youtube.com/watch?v=Bl2rca9HPRM)
        * [Trigger word detection](https://www.youtube.com/watch?v=KofGXJhbXBc&feature=youtu.be)
    * Programming assignments
        * Neural Machine Translation with Attention: in this exercise, I build a Neural Machine Translation (NMT) model, which translate human readable dates ("25th of June, 2009") into machine readable dates ("2009-06-25"). This is being achieved using an attention model.
        * Trigger word detection: here I practiced converting audio clip into spectrogram and built a sequence model consisting of a 1-D convolution layer and GRUs.

**Thoughts:** 

Today I finished my roughly 6-weeks sprint of the deep learning specialization from [deeplearning.ai](https://www.deeplearning.ai/). I realized just as Andrew Ng said, deep learning is such a super power that normal people like you and me can use it to make huge changes to this world and eventually make this world a better place. 


**Link to work:** 

[Certificate for my deep learning specialization](https://www.coursera.org/account/accomplishments/specialization/R4Z7GGNP8LEF).

## Day 4: July 10, 2018 

**Today's Progress**: 
* Reviewed Coursera videos about RNN, gradient vanishing problems of RNN and GRU.
* Started the [Practical Reinforcement Learning](https://www.coursera.org/learn/practical-rl) course on Coursera. Learned about Markov Decision Process and crossentropy method for reinforcement learning. I am still stuck at setting up its development environment with [Kitematic][Kitematic]/[Docker][Docker].

[Kitematic]: https://kitematic.com/
[Docker]: https://www.docker.com/

**Thoughts:** None for today.

## Day 5: July 11, 2018 

**Today's Progress**: 
* Finished setting up [Practical Reinforcement Learning](https://www.coursera.org/learn/practical-rl) git [repo](https://github.com/Maverobot/Practical_RL) with [Kitematic][Kitematic]/[Docker][Docker] on my local PC.
* Played around a little bit with `gym`.

## Day 6: July 12, 2018 

**Today's Progress**: 
* Used crossentropy method to solve the `Taxi-v2` problem.

**Thoughts:**
I am still not familiar with python. So much time was wasted just because I did not know in `for item in items` the `item` is not a reference. It seems that I need a organized learning session for python. 

**Link to work:** 
[Crossentropy method notebook](https://github.com/Maverobot/Practical_RL/blob/practice_work_through/week1_intro/crossentropy_method.ipynb).

## Day 7: July 13, 2018 

**Today's Progress**: 
* Started writing a reinforcement learning [script](https://github.com/Maverobot/rl_playground/blob/master/examples/carthole.py) solving [CartPole-v0](https://gym.openai.com/envs/CartPole-v0/) from scratch. Getting familiar with setting up `gym` and managing states as well as actions.

## Day 8: July 14, 2018 

**Today's Progress**: 
* Further worked on my Q learning [script](https://github.com/Maverobot/rl_playground/blob/master/examples/carthole.py) solving [CartPole-v0](https://gym.openai.com/envs/CartPole-v0/). Rough structure is done but it still needs debugging.

## Day 9: July 15, 2018 

**Today's Progress**: 
* My first hand written Q learning [script](https://github.com/Maverobot/rl_playground/blob/master/examples/carthole.py) worked and converged to a relative good result.

**Thoughts:**
* Some bugs that I fixed today were caused by missunderstanding of the concept. Next time before writing down the code, I should always make sure I fully understand the math and intuition behind it.
* I encountered instability in `softmax` function. The instability issue can be solved by substracting the max the all elements. The sample code could be look like:
  ```
  max_a = np.max(actions_set)
  logits_exp = np.exp(actions_set - max_a)
  probs = logits_exp / np.sum(logits_exp)
  ```

## Day 10: July 16, 2018 

**Today's Progress**: 
* Tried to understand how `tensorflow.js` works by reading an example [project](https://github.com/tensorflow/tfjs-examples/tree/master/polynomial-regression-core). Due to the lack of knowledge of `javascript`, I did not make too far.

## Day 11: July 17, 2018 

**Today's Progress**: 
* Decided to use the `CartPole` problem as example to practicing `tensorflow` and started reimplementing Q learning using `tensorflow`. The code is [here](https://github.com/Maverobot/ml_playground/blob/master/rl_examples/tf_carthole.py).

## Day 12: July 18, 2018 

**Today's Progress**: 
* I have recently just barely 1 hour for maching learning and this will last until 26.07.2018. Today I finished my draft of `tensorflow` version Q learning. However, it still does not converge and remains to be fixed. 

## Day 13: July 19, 2018 

**Today's Progress**: 
* Further polished the `tensorflow` version of Q learning, which seems really slow to converge. In order to fix this problem more oriented, I started watching this [video](https://www.youtube.com/watch?v=Vz5l886eptw) which hopefully makes me better understand the issue. 

## Day 14: July 20, 2018 

**Today's Progress**: 
* Still stuggling making my code converge to solve the cartpole problem.
* Watched the videos: Training a neural network to play a game with TensorFlow and Open AI [1](https://www.youtube.com/watch?v=3zeg7H6cAJw) [2](https://www.youtube.com/watch?v=RVt4EN-XdPA) [3](https://www.youtube.com/watch?v=G-KvpNGudLw) [4](https://www.youtube.com/watch?v=HCBX2cuA5UU&t=5s)

**Thoughts:**
* I am still lack the skill to fully utilize tensorflow. My next short term plan would be becoming familiar with tensorflow.

## Day 15: July 21, 2018 

**Today's Progress**: 
* Started the course [Deep Learning with TensorFlow](https://cognitiveclass.ai/courses/deep-learning-tensorflow/) on [Cognitive Class](https://cognitiveclass.ai/). Relearned basics of `tensorflow`.

## Day 16: July 22, 2018 

**Today's Progress**: 
* Written `tensorflow` scripts to detect digits in MNIST dataset. 
    * [Multi-layer perceptron](https://github.com/Maverobot/ml_playground/blob/master/tensforflow_learn/2_multilayer_perceptron_mnist.py)
    * [Convolutional Neural Network](https://github.com/Maverobot/ml_playground/blob/master/tensforflow_learn/3_cnn_mnist.py)

## Day 17: July 23, 2018 

**Today's Progress**: 
* Read the paper [One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning](https://arxiv.org/abs/1802.01557). In the paper, the author presents a method combining model-agnostic meta-learning algorithm (MAML) and 1D convolution layers, which enables robots to imitate the task shown by a human from a video. Although the video in test phase could have different similar objects and human demonstrator, a completely new task still cannot be inferred by the method. 

## Day 18: July 24, 2018 

**Today's Progress**: 
* For better understanding reinforcement learning, I started reading book [Reinforcement Learning: An Introduction Second edition](http://incompleteideas.net/book/bookdraft2017nov5.pdf). Progress: till chapter 1.3. 

## Day 19: July 25, 2018 

**Today's Progress**: 
* Continued reading book [Reinforcement Learning: An Introduction Second edition](http://incompleteideas.net/book/bookdraft2017nov5.pdf). Progress: till chapter 1.7. 

## Day 20: July 26, 2018 

**Today's Progress**: 
* Continued reading book [Reinforcement Learning: An Introduction Second edition](http://incompleteideas.net/book/bookdraft2017nov5.pdf). Progress: till chapter 2.2. 
